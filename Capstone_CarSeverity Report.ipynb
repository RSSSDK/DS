{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Car accident severity Report (Week 2)\n",
    "### Applied Data Science Capstone by IBM/Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction: Business Problem <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the increase in the number of cars and the raise of accidents happened in the roads too, this cause injuries or fatalities to people, waste time and cost for police and rescue vehicles, traffic delay in the area.\n",
    "\n",
    "The Seattle Department of Transportation (SODT) objective to improve new model aims to predict the severity of car accidents and main variables that strongly related to it, in order to help decisions based to make campaigns or improvements to decrease severe accidents based on certain conditions. And detect intersection have car accidents with hight servity ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Understanding**\n",
    "\n",
    "In this phase, and based on definition of our problem, many factors that will influence our decission . I will use csv file provided by Coursera. The main attributes I will use as independent variables are: WEATHER, ROADCOND and LIGHTCOND, that adequate to train my machine learning model. Also, I will assess the condition of these attributes by looking for skewed information and the correlations between them and the severity of the accident, so the \"SEVERITYCODE\" used as labeld data  property damage (class 1) or injury (class 2) .\n",
    "\n",
    "**Data preparation**\n",
    "\n",
    "In this phase I will build the final dataset that fed my model by:\n",
    "\n",
    "    *Filling missing data\n",
    "    * Decodes categoral data\n",
    "    *Finally, balance and normalize all data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methodolegy**\n",
    "\n",
    "After the data prepeared and processed i will splitt it by 0.3.\n",
    "\n",
    "We will use the following models:\n",
    "\n",
    "        1) K-Nearest Neighbor (KNN)\n",
    "           KNN will help us predict the severity code of an outcome by finding the most similar to data point within k distance.\n",
    "\n",
    "        2)  Decision Tree\n",
    "            A decision tree model gives us a layout of all possible outcomes so we can fully analyze the concequences of a decision. It context, the decision tree observes \n",
    "            all possible outcomes of different weather conditions.\n",
    "\n",
    "       3) Logistic Regression\n",
    "          Because our dataset only provides us with two severity code outcomes, our model will only predict one of those two classes. This makes our data binary, which is \n",
    "          perfect to use with logistic regression.\n",
    "\n",
    "Then evaluate the models based on test data and select the highest F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation using Test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Algorithm           Jaccard F1-score Logloss \n",
    "\n",
    "KNN                    0.56     0.54      NA\n",
    "\n",
    "Decision Tree          0.56     0.49      NA\n",
    "\n",
    "Logistic Regression    0.53     0.51    0.68\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginning of this notebook, we had categorical data that need to encoded becuase they not a data type that we could have fed through an algoritim, so label encoding was used to created new classes that were of type int8; a numerical data type.\n",
    "\n",
    "After that issue we were presented with another  imbalanced of data. As mentioned earlier, class 1 was nearly three times larger than class 2, So the solution to this was resampling the majority class to 58188 values each.\n",
    "\n",
    "Once we analyzed and cleaned the data, it was then fed through three ML models; K-Nearest Neighbor, Decision Tree and Logistic Regression. Although the first two are ideal for this project, logistic regression made most sense because of its binary nature.\n",
    "\n",
    "Evaluation metrics used to test the accuracy of our models were jaccard index, f-1 score and logloss for logistic regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on historical data from weather conditions pointing to certain classes, we can conclude that particular weather conditions have a somewhat impact on whether or not travel could result in property damage (class 1) or injury (class 2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
