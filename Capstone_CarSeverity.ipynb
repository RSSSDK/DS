{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Car accident severity  (Week 2)\n",
    "### Applied Data Science Capstone by IBM/Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction: Business Problem <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the increase in the number of cars and the raise of accidents happened in the roads too, this cause injuries or fatalities to people, waste time and cost for police and rescue vehicles, traffic delay in the area.\n",
    "\n",
    "The Seattle Department of Transportation (SODT) objective to improve new model aims to predict the severity of car accidents and main variables that strongly related to it, in order to help decisions based to make campaigns or improvements to decrease severe accidents based on certain conditions. And detect intersection have car accidents with hight servity ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Understanding**\n",
    "\n",
    "In this phase, and based on definition of our problem, many factors that will influence our decission . I will use csv file provided by Coursera. The main attributes I will use as independent variables are: WEATHER, ROADCOND and LIGHTCOND, that adequate to train my machine learning model. Also, I will assess the condition of these attributes by looking for skewed information and the correlations between them and the severity of the accident, so the \"SEVERITYCODE\" used as labeld data  property damage (class 1) or injury (class 2) .\n",
    "\n",
    "**Data preparation**\n",
    "\n",
    "In this phase I will build the final dataset that fed my model by:\n",
    "\n",
    "    *Filling missing data\n",
    "    * Decodes categoral data\n",
    "    *Finally, balance and normalize all data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methodolegy**\n",
    "\n",
    "After the data prepeared and processed i will splitt it by 0.3.\n",
    "\n",
    "We will use the following models:\n",
    "\n",
    "        K-Nearest Neighbor (KNN)\n",
    "        KNN will help us predict the severity code of an outcome by finding the most similar to data point within k distance.\n",
    "\n",
    "        Decision Tree\n",
    "        A decision tree model gives us a layout of all possible outcomes so we can fully analyze the concequences of a decision. It context, the decision tree observes all possible outcomes of different weather conditions.\n",
    "\n",
    "        Logistic Regression\n",
    "        Because our dataset only provides us with two severity code outcomes, our model will only predict one of those two classes. This makes our data binary, which is perfect to use with logistic regression.\n",
    "Then make evaluation on test data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data-Collisions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Dark - Street Lights On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEVERITYCODE   WEATHER ROADCOND                LIGHTCOND\n",
       "0             2  Overcast      Wet                 Daylight\n",
       "1             1   Raining      Wet  Dark - Street Lights On\n",
       "2             1  Overcast      Dry                 Daylight\n",
       "3             1     Clear      Dry                 Daylight\n",
       "4             2   Raining      Wet                 Daylight"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.drop(columns = [\"SEVERITYCODE.1\",\"X\",\"Y\",\"OBJECTID\",\"INCKEY\",\"COLDETKEY\",\"REPORTNO\",\"STATUS\",\"ADDRTYPE\",\"INTKEY\",\"LOCATION\",\"EXCEPTRSNCODE\",\"EXCEPTRSNDESC\",\"SEVERITYDESC\",\"COLLISIONTYPE\",\"PERSONCOUNT\",\"PEDCOUNT\",\"PEDCYLCOUNT\",\"VEHCOUNT\",\"INCDATE\",\"INCDTTM\",\"JUNCTIONTYPE\",\"SDOT_COLCODE\",\"SDOT_COLDESC\",\"INATTENTIONIND\",\"UNDERINFL\",\"PEDROWNOTGRNT\",\"SDOTCOLNUM\",\"SPEEDING\",\"ST_COLCODE\",\"ST_COLDESC\",\"SEGLANEKEY\",\"CROSSWALKKEY\",\"HITPARKEDCAR\"] )\n",
    "dataset.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Missing Data and Uniques Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEVERITYCODE     2\n",
       "WEATHER         11\n",
       "ROADCOND         9\n",
       "LIGHTCOND        9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEVERITYCODE       0\n",
       "WEATHER         5081\n",
       "ROADCOND        5012\n",
       "LIGHTCOND       5170\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change categories  to Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"WEATHER\"] = dataset[\"WEATHER\"].astype('category')\n",
    "dataset[\"ROADCOND\"] = dataset[\"ROADCOND\"].astype('category')\n",
    "dataset[\"LIGHTCOND\"] = dataset[\"LIGHTCOND\"].astype('category')\n",
    "\n",
    "dataset[\"WEATHER_CAT\"] = dataset[\"WEATHER\"].cat.codes\n",
    "dataset[\"ROADCOND_CAT\"] = dataset[\"ROADCOND\"].cat.codes\n",
    "dataset[\"LIGHTCOND_CAT\"] = dataset[\"LIGHTCOND\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "      <th>WEATHER_CAT</th>\n",
       "      <th>ROADCOND_CAT</th>\n",
       "      <th>LIGHTCOND_CAT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132488</td>\n",
       "      <td>132533</td>\n",
       "      <td>132405</td>\n",
       "      <td>136485</td>\n",
       "      <td>136485</td>\n",
       "      <td>136485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57104</td>\n",
       "      <td>57128</td>\n",
       "      <td>57098</td>\n",
       "      <td>58188</td>\n",
       "      <td>58188</td>\n",
       "      <td>58188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              WEATHER  ROADCOND  LIGHTCOND  WEATHER_CAT  ROADCOND_CAT  \\\n",
       "SEVERITYCODE                                                            \n",
       "1              132488    132533     132405       136485        136485   \n",
       "2               57104     57128      57098        58188         58188   \n",
       "\n",
       "              LIGHTCOND_CAT  \n",
       "SEVERITYCODE                 \n",
       "1                    136485  \n",
       "2                     58188  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby([\"SEVERITYCODE\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample \n",
    "\n",
    "dataset_1 = dataset[dataset.SEVERITYCODE==1]\n",
    "dataset_2 = dataset[dataset.SEVERITYCODE==2]\n",
    "\n",
    "datset_1_sample = resample(dataset_1,replace = False ,n_samples=58188,random_state=99)\n",
    "\n",
    "datset_balanced =  pd.concat( [datset_1_sample,dataset_2] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "X = np.asarray(datset_balanced[[\"WEATHER_CAT\",\"ROADCOND_CAT\",\"LIGHTCOND_CAT\"]])\n",
    "y = np.asarray(datset_balanced[\"SEVERITYCODE\"])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test ,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by Model <a name=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform some models (Logistc,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Using Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LRBest = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Ks = 10\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat=neigh.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)  \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "KNNBest = KNeighborsClassifier(n_neighbors = mean_acc.argmax()+1).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)  DecisionTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Ks = 10\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    \n",
    "    DTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = n)\n",
    "    DTree.fit(X_train,y_train)\n",
    "    yhat=DTree.predict(X_test)\n",
    "    \n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "DTreeBest = DecisionTreeClassifier(criterion=\"entropy\", max_depth = mean_acc.argmax()+1).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation using Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm           Jaccard F1-score Logloss\n",
      "KNN                    0.56     0.54      NA\n",
      "Decision Tree          0.56     0.49      NA\n",
      "Logistic Regression    0.53     0.51    0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "yhat = KNNBest.predict(X_test) \n",
    "KNNJss = '{:0.2f}'.format(jaccard_similarity_score(y_test, yhat))\n",
    "KNNF1 =  '{:0.2f}'.format(f1_score(y_test, yhat, average='weighted'))\n",
    "\n",
    "yhat = DTreeBest.predict(X_test) \n",
    "DTJss =  '{:0.2f}'.format(jaccard_similarity_score(y_test, yhat))\n",
    "DTF1 = '{:0.2f}'.format(f1_score(y_test, yhat, average='weighted'))\n",
    "\n",
    "\n",
    "yhat = LRBest.predict(X_test)\n",
    "yhatprob = LRBest.predict_proba(X_test)\n",
    "LRJss =  '{:0.2f}'.format(jaccard_similarity_score(y_test, yhat))\n",
    "LRF1 = '{:0.2f}'.format(f1_score(y_test, yhat, average='weighted'))\n",
    "LRlog = '{:0.2f}'.format(log_loss(y_test, yhatprob))\n",
    "\n",
    "data = np.array([['Algorithm','Jaccard', 'F1-score', 'Logloss'],\n",
    "                ['KNN',KNNJss,KNNF1,'NA'],\n",
    "                ['Decision Tree',DTJss,DTF1,'NA'],\n",
    "               # ['SVM',SVMJss,SVMF1,'NA'],\n",
    "                ['Logistic Regression',LRJss,LRF1,LRlog]\n",
    "                \n",
    "                ])\n",
    "\n",
    "Reportdf = pd.DataFrame(data=data[1:,1:],\n",
    "                  index=data[1:,0],\n",
    "                  columns=data[0,1:])\n",
    "Reportdf.columns.name = 'Algorithm'\n",
    "\n",
    "print(Reportdf   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginning of this notebook, we had categorical data that need to encoded becuase they not a data type that we could have fed through an algoritim, so label encoding was used to created new classes that were of type int8; a numerical data type.\n",
    "\n",
    "After that issue we were presented with another  imbalanced of data. As mentioned earlier, class 1 was nearly three times larger than class 2, So the solution to this was resampling the majority class to 58188 values each.\n",
    "\n",
    "Once we analyzed and cleaned the data, it was then fed through three ML models; K-Nearest Neighbor, Decision Tree and Logistic Regression. Although the first two are ideal for this project, logistic regression made most sense because of its binary nature.\n",
    "\n",
    "Evaluation metrics used to test the accuracy of our models were jaccard index, f-1 score and logloss for logistic regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on historical data from weather conditions pointing to certain classes, we can conclude that particular weather conditions have a somewhat impact on whether or not travel could result in property damage (class 1) or injury (class 2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
